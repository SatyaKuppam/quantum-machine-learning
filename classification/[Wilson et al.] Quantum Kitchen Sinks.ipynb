{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirq.contrib.svg import SVGCircuit\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mnist import MNISTData\n",
    "\n",
    "import scipy\n",
    "import cirq\n",
    "import numpy as np\n",
    "import tensorflow_quantum as tfq\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12108, 784) (1346, 784)\n",
      "(1600, 784) (400, 784)\n"
     ]
    }
   ],
   "source": [
    "mnist_data = MNISTData(seed)\n",
    "X_train, X_test, y_train, y_test = mnist_data.get_three_five_test_train_split()\n",
    "train_indices = np.random.randint(0, X_train.shape[0], 1600)\n",
    "test_indices = np.random.randint(0, X_test.shape[0], 400)\n",
    "\n",
    "X_tr = X_train[train_indices]\n",
    "y_tr = y_train[train_indices]\n",
    "X_te = X_test[test_indices]\n",
    "y_te = y_test[test_indices]\n",
    "print(X_tr.shape, X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoQubitQks:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, episodes=100):\n",
    "        self.qubits = cirq.LineQubit.range(2)\n",
    "        # the number of qubits\n",
    "        self.q = 2\n",
    "        self.p = X_train.shape[1]\n",
    "        self.r = self.p/self.q\n",
    "        self.E = episodes\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.X_test = X_test\n",
    "        # mask = q * p\n",
    "        mask = np.ones((self.q, self.p))\n",
    "        mask[0,:int(self.r)], mask[1,int(self.r):] = 0.0, 0.0\n",
    "        self.mask = mask.reshape(self.q*self.p)\n",
    "    \n",
    "    def _get_ansatz(self, theta, draw=False):\n",
    "        circuit = cirq.Circuit()\n",
    "        circuit.append(cirq.rx(theta[0])(self.qubits[0]))\n",
    "        circuit.append(cirq.rx(theta[1])(self.qubits[1]))\n",
    "        circuit.append(cirq.CNOT(self.qubits[0], self.qubits[1]))\n",
    "        circuit.append(cirq.measure(self.qubits[1]))\n",
    "        \n",
    "        if draw:\n",
    "            SVGCircuit(circuit)    \n",
    "        return circuit\n",
    "    \n",
    "    def _get_meas(self, theta):\n",
    "        circuit = self._get_ansatz(theta)\n",
    "        result = cirq.Simulator().run(circuit)\n",
    "        return -1 if result.measurements['1'][0][0] == 0 else 1\n",
    "    \n",
    "    def _get_omega_and_beta(self, variance):\n",
    "        stddev = variance ** 2\n",
    "        # mask = E x q x p\n",
    "        mask = self.mask.repeat(self.E)\n",
    "        # mask = (E x (q*p))\n",
    "        mask = mask.reshape((self.E, self.q*self.p))\n",
    "        # omega_e = (E x (q*p))\n",
    "        omega_e = np.random.normal(0.0, stddev, (self.E, (self.q * self.p)))\n",
    "        # omega = (mask * omega_e) so (E x (q*p))\n",
    "        omega = mask * omega_e\n",
    "        # omega = (E x p x q)\n",
    "        omega = omega.reshape((self.E, self.p, self.q), order='F')\n",
    "        # beta = (E x q)\n",
    "        beta = np.random.uniform(0.0, 2 * np.pi, (self.E, self.q))\n",
    "        return omega, beta\n",
    "    \n",
    "    def _get_embeddings(self, variance):\n",
    "        omega, beta = self._get_omega_and_beta(variance)\n",
    "        # params = (n x E x q)\n",
    "        params = self.X_train.dot(omega) + beta\n",
    "        # params = (n * E) x q\n",
    "        return params.reshape((params.shape[0] * params.shape[1], params.shape[2]))\n",
    "        \n",
    "    def _loss(self, variance):\n",
    "        # labels = (n * E)\n",
    "        labels = np.tile(self.y_train, self.E)\n",
    "        params = self._get_embeddings(variance)\n",
    "        \n",
    "        # get predictions\n",
    "        preds = np.array([self._get_meas(param) for param in params])\n",
    "        # get loss\n",
    "        return mean_squared_error(preds, labels)\n",
    "    \n",
    "    def train(self):\n",
    "        result = scipy.optimize.minimize_scalar(self._loss)\n",
    "        self.variance = result['x']\n",
    "        print(result)\n",
    "        \n",
    "    def test_accuracy(self):\n",
    "        stddev = self.variance ** 2\n",
    "        n = self.X_test.shape[0]\n",
    "        omega = np.random.normal(0.0, stddev, (self.p, self.q)) * self.mask.reshape((self.p, self.q))\n",
    "        beta = np.random.uniform(0.0, 2 * np.pi, (self.q,))\n",
    "        \n",
    "        params = self.X_test.dot(omega)\n",
    "        preds = np.array([self._get_meas(param) for param in params])\n",
    "        return (np.sum(preds == self.y_test)/preds.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoQubitQks = TwoQubitQks(X_tr, y_tr, X_te, y_te, episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow: auto; white-space: pre;\">0: ───Rx(π)───@───────\n",
       "              │\n",
       "1: ───Rx(π)───X───M───</pre>"
      ],
      "text/plain": [
       "0: ───Rx(π)───@───────\n",
       "              │\n",
       "1: ───Rx(π)───X───M───"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoQubitQks._get_ansatz([np.pi, np.pi], draw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoQubitQks.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1568,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55.50000000000001"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoQubitQks.test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a QKS layer that extends keras Layer\n",
    "class TwoQubitQKSAnsatzLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, qubits, uniform_min_value=0.0, uniform_max_value=2.0 * np.pi, stddev=0.1):\n",
    "        super(TwoQubitQKSAnsatzLayer, self).__init__()\n",
    "        self.q = 2 # because two qubits, variable names q, p, r are the same as in Wilson et al.\n",
    "        self.stddev = tf.Variable(initial_value=stddev, trainable=True)\n",
    "        self.uniform_min_value = 0.0\n",
    "        self.uniform_max_value = 2.0 * np.pi\n",
    "        self.qubits = qubits\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # creates a mask, which will stay contant throught\n",
    "        p = input_shape[-1]\n",
    "        self.r = int(p/self.q)\n",
    "    \n",
    "    def _ansatz(self, theta):\n",
    "        print(float(theta[0]))\n",
    "        # theta = theta.numpy()\n",
    "        circuit = cirq.Circuit()\n",
    "        circuit.append(cirq.rx(float(theta[0]))(self.qubits[0]))\n",
    "        circuit.append(cirq.rx(float(theta[1]))(self.qubits[1]))\n",
    "        circuit.append(cirq.CNOT(self.qubits[0], self.qubits[1]))\n",
    "        \n",
    "        circuit.append(cirq.measure(self.qubits[0]))\n",
    "        circuit.append(cirq.measure(self.qubits[1]))\n",
    "        return circuit\n",
    "    \n",
    "    def I(self):\n",
    "        # just a Identity circuit for the PQC layer\n",
    "        # when you create the model\n",
    "        circuit = cirq.Circuit()\n",
    "        circuit.append(cirq.I(self.qubits[0]))\n",
    "        circuit.append(cirq.I(self.qubits[1]))\n",
    "        return circuit\n",
    "        \n",
    "    def call(self, input):\n",
    "        p = input.shape[-1]\n",
    "        \n",
    "        ones, mask = np.ones((self.q, p)), np.random.randint(0, 2, self.q)\n",
    "        ones[mask==0,:self.r], ones[mask==1,self.r:] = 0.0, 0.0\n",
    "        self.mask = ones.reshape((self.q, p))\n",
    "        \n",
    "        omega = tf.random.normal((self.q, p), mean=0.0, stddev=self.stddev) * self.mask\n",
    "        beta = tf.random.uniform((self.q,), self.uniform_min_value, self.uniform_max_value)\n",
    "        \n",
    "        parameters = tf.linalg.matvec(omega, input) + beta\n",
    "        return tfq.convert_to_tensor([self._ansatz(parameters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits = cirq.GridQubit.rect(1,2)\n",
    "qks_ansatz = TwoQubitQKSAnsatzLayer(qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.1>]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qks_ansatz.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4427309036254883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([1])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tf.random.normal((10,), mean=0.0, stddev=1.0)\n",
    "qks_ansatz(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"334.38546875000003\" height=\"100.0\"><line x1=\"34.7588671875\" x2=\"304.38546875000003\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"304.38546875000003\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"204.38546875000003\" x2=\"204.38546875000003\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(0, 1): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"84.86773437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"121.9516015625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">Rx(0.159π)</text><rect x=\"79.517734375\" y=\"55.0\" width=\"84.86773437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"121.9516015625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">Rx(0.191π)</text><circle cx=\"204.38546875000003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"184.38546875000003\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"204.38546875000003\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\">X</text><rect x=\"244.38546875000003\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"264.38546875000003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\">M</text><rect x=\"244.38546875000003\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"264.38546875000003\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\">M</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7fde8f661dd8>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVGCircuit(qks_ansatz._ansatz(tf.convert_to_tensor([0.5, 0.6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumKitchenSinks:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "    \n",
    "    def _mnist_model_compile(self, learning_rate):\n",
    "        cluster_state_bits = cirq.GridQubit.rect(1,2)\n",
    "        readout_operators = [cirq.Z(cluster_state_bits[0]), cirq.Z(cluster_state_bits[1])]\n",
    "        \n",
    "        \n",
    "        model = tf.keras.Sequential([\n",
    "            TwoQubitQKSAnsatzLayer(qubits),\n",
    "            tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)\n",
    "        ])\n",
    "        \n",
    "#         inputs = tf.keras.Input(shape=(784,), name=\"digits\")\n",
    "#         ansatz = TwoQubitQKSAnsatzLayer(qubits)\n",
    "#         quantum_circuits = ansatz(inputs)\n",
    "#         expectation_layer = tfq.layers.PQC(quantum_circuits.I(), readout_operators)\n",
    "#         expec_outputs = expectation_layer(quantum_circuits)\n",
    "#         outputs = tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)(expec_outputs)\n",
    "#         model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=tf.keras.losses.categorical_crossentropy)\n",
    "        # tf.keras.utils.plot_model(model, show_shapes=True, dpi=70)\n",
    "        self.mnist_model = model\n",
    "    \n",
    "    def mnist_model_fit(self, epochs=10, learning_rate=0.01, batch_size=500):\n",
    "        self._mnist_model_compile(learning_rate=learning_rate)\n",
    "        history = self.mnist_model.fit(x=self.X_train, y=self.y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title(\"Binary Classification for MNIST data set on 0,1 digits\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Error in classification\")\n",
    "        plt.show()\n",
    "        print(\"Final loss value:\")\n",
    "        print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.global_variables_initializer()\n",
    "quantum_kitchen_sinks_model = QuantumKitchenSinks(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sequential_4/two_qubit_qks_ansatz_layer_31/strided_slice:0\", shape=(2,), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Device.validate_operation of cirq.UNCONSTRAINED_DEVICE> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (tmpv8y6hvhs.py, line 16)\n",
      "WARNING: AutoGraph could not transform <bound method Device.validate_operation of cirq.UNCONSTRAINED_DEVICE> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (tmpv8y6hvhs.py, line 16)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Device.validate_operation of cirq.UNCONSTRAINED_DEVICE> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (tmps31j_5s3.py, line 16)\n",
      "WARNING: AutoGraph could not transform <bound method Device.validate_operation of cirq.UNCONSTRAINED_DEVICE> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (tmps31j_5s3.py, line 16)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Device.validate_operation of cirq.UNCONSTRAINED_DEVICE> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (tmppmdoy1nz.py, line 16)\n",
      "WARNING: AutoGraph could not transform <bound method Device.validate_operation of cirq.UNCONSTRAINED_DEVICE> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (tmppmdoy1nz.py, line 16)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Device.validate_operation of cirq.UNCONSTRAINED_DEVICE> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (tmp0t82q0rn.py, line 16)\n",
      "WARNING: AutoGraph could not transform <bound method Device.validate_operation of cirq.UNCONSTRAINED_DEVICE> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (tmp0t82q0rn.py, line 16)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Device.validate_operation of cirq.UNCONSTRAINED_DEVICE> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (tmp9wrwrp6x.py, line 16)\n",
      "WARNING: AutoGraph could not transform <bound method Device.validate_operation of cirq.UNCONSTRAINED_DEVICE> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (tmp9wrwrp6x.py, line 16)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-131-9a4db7340c07>:47 call  *\n        return tfq.convert_to_tensor([self._ansatz(parameters)])\n    /home/satya/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py:292 wrapper\n        return func(*args, **kwargs)\n    /home/satya/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_quantum/python/util.py:190 convert_to_tensor\n        return tf.convert_to_tensor(recur(items_to_convert))\n    /home/satya/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_quantum/python/util.py:182 recur\n        serializer.serialize_circuit(item).SerializeToString())\n    /home/satya/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_quantum/core/serialize/serializer.py:385 serialize_circuit\n        circuit = copy.deepcopy(circuit_inp)\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:215 _deepcopy_list\n        append(deepcopy(a, memo))\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:220 _deepcopy_tuple\n        y = [deepcopy(a, memo) for a in x]\n    /usr/lib/python3.6/copy.py:220 <listcomp>\n        y = [deepcopy(a, memo) for a in x]\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:169 deepcopy\n        rv = reductor(4)\n\n    TypeError: can't pickle _thread.RLock objects\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-e76507baf867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquantum_kitchen_sinks_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist_model_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-179d190f00d9>\u001b[0m in \u001b[0;36mmnist_model_fit\u001b[0;34m(self, epochs, learning_rate, batch_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmnist_model_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mnist_model_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Binary Classification for MNIST data set on 0,1 digits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2344\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2346\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2347\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2570\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2572\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2657\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    772\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    772\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-131-9a4db7340c07>:47 call  *\n        return tfq.convert_to_tensor([self._ansatz(parameters)])\n    /home/satya/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py:292 wrapper\n        return func(*args, **kwargs)\n    /home/satya/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_quantum/python/util.py:190 convert_to_tensor\n        return tf.convert_to_tensor(recur(items_to_convert))\n    /home/satya/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_quantum/python/util.py:182 recur\n        serializer.serialize_circuit(item).SerializeToString())\n    /home/satya/code/quantum-machine-learning/quantum_machine_learning/lib/python3.6/site-packages/tensorflow_quantum/core/serialize/serializer.py:385 serialize_circuit\n        circuit = copy.deepcopy(circuit_inp)\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:215 _deepcopy_list\n        append(deepcopy(a, memo))\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:220 _deepcopy_tuple\n        y = [deepcopy(a, memo) for a in x]\n    /usr/lib/python3.6/copy.py:220 <listcomp>\n        y = [deepcopy(a, memo) for a in x]\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:180 deepcopy\n        y = _reconstruct(x, memo, *rv)\n    /usr/lib/python3.6/copy.py:280 _reconstruct\n        state = deepcopy(state, memo)\n    /usr/lib/python3.6/copy.py:150 deepcopy\n        y = copier(x, memo)\n    /usr/lib/python3.6/copy.py:240 _deepcopy_dict\n        y[deepcopy(key, memo)] = deepcopy(value, memo)\n    /usr/lib/python3.6/copy.py:169 deepcopy\n        rv = reductor(4)\n\n    TypeError: can't pickle _thread.RLock objects\n"
     ]
    }
   ],
   "source": [
    "quantum_kitchen_sinks_model.mnist_model_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
