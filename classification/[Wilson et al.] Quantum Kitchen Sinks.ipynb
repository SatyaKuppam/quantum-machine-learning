{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Kitchen Sinks by Wilson et al.[1]\n",
    "\n",
    "### Algorithm:\n",
    "\n",
    "Given a dataset $\\{y_i, u_i\\}_{i=1..m}$ of $m$ points where $u_i \\in \\mathbb{R}^p$ and a set of $E$ feature vectors derived from $u$, also called 'episodes'[1]. The E.R.M is:\n",
    "$$arg\\min\\limits_{\\sigma \\in \\mathbb{R}} \\sum\\limits_{e=1}^{|E|} \\frac{1}{m}\\sum\\limits_{i=1}^{M}c(\\Phi_e(\\theta_e, u_i), y_i)$$\n",
    "\n",
    "Where $c$ is the cost function, where $\\theta_e$ are the gate parameters for each episode, \n",
    "$$\\Omega_e \\in \\mathbb{R}^{q \\times p}; \\beta_e \\in \\mathbb{R}^q$$\n",
    "$$\\theta_{i, e} = \\Omega_eu_i + \\beta_e$$\n",
    "with $$u \\in \\mathbb{R}^{n\\times p}; \\theta_e = u \\Omega_e^T + \\beta_e$$\n",
    "$$\\Omega_e \\sim \\mathcal{N}(0, \\sigma^2)); \\beta_e \\sim \\mathcal{U}(0, 2\\pi)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cirq.contrib.svg import SVGCircuit\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mnist import MNISTData\n",
    "\n",
    "import scipy\n",
    "import cirq\n",
    "import numpy as np\n",
    "import tensorflow_quantum as tfq\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 784) (400, 784)\n"
     ]
    }
   ],
   "source": [
    "mnist_data = MNISTData(seed)\n",
    "X_train, X_test, y_train, y_test = mnist_data.get_three_five_test_train_split()\n",
    "train_indices = np.random.randint(0, X_train.shape[0], 1600)\n",
    "test_indices = np.random.randint(0, X_test.shape[0], 400)\n",
    "\n",
    "X_tr = X_train[train_indices]\n",
    "y_tr = y_train[train_indices]\n",
    "X_te = X_test[test_indices]\n",
    "y_te = y_test[test_indices]\n",
    "print(X_tr.shape, X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoQubitQks:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, episodes=100):\n",
    "        self.qubits = cirq.LineQubit.range(2)\n",
    "        # the number of qubits\n",
    "        self.q = 2\n",
    "        self.p = X_train.shape[1]\n",
    "        self.r = self.p/self.q\n",
    "        self.E = episodes\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.X_test = X_test\n",
    "        # mask = q * p\n",
    "        mask = np.ones((self.q, self.p))\n",
    "        mask[0,:int(self.r)], mask[1,int(self.r):] = 0.0, 0.0\n",
    "        self.mask = mask.reshape(self.q*self.p)\n",
    "    \n",
    "    def _get_ansatz(self, theta, draw=False):\n",
    "        circuit = cirq.Circuit()\n",
    "        circuit.append(cirq.rx(theta[0])(self.qubits[0]))\n",
    "        circuit.append(cirq.rx(theta[1])(self.qubits[1]))\n",
    "        circuit.append(cirq.CNOT(self.qubits[0], self.qubits[1]))\n",
    "        circuit.append(cirq.measure(self.qubits[1]))\n",
    "        \n",
    "        if draw:\n",
    "            SVGCircuit(circuit)    \n",
    "        return circuit\n",
    "    \n",
    "    def _get_meas(self, theta):\n",
    "        circuit = self._get_ansatz(theta)\n",
    "        result = cirq.Simulator().run(circuit)\n",
    "        return -1 if result.measurements['1'][0][0] == 0 else 1\n",
    "    \n",
    "    def _get_omega_and_beta(self, variance):\n",
    "        stddev = variance ** 2\n",
    "        # mask = E x q x p\n",
    "        mask = self.mask.repeat(self.E)\n",
    "        # mask = (E x (q*p))\n",
    "        mask = mask.reshape((self.E, self.q*self.p))\n",
    "        # omega_e = (E x (q*p))\n",
    "        omega_e = np.random.normal(0.0, stddev, (self.E, (self.q * self.p)))\n",
    "        # omega = (mask * omega_e) so (E x (q*p))\n",
    "        omega = mask * omega_e\n",
    "        # omega = (E x p x q)\n",
    "        omega = omega.reshape((self.E, self.p, self.q), order='F')\n",
    "        # beta = (E x q)\n",
    "        beta = np.random.uniform(0.0, 2 * np.pi, (self.E, self.q))\n",
    "        return omega, beta\n",
    "    \n",
    "    def _get_embeddings(self, variance):\n",
    "        omega, beta = self._get_omega_and_beta(variance)\n",
    "        # params = (n x E x q)\n",
    "        params = self.X_train.dot(omega) + beta\n",
    "        # params = (n * E) x q\n",
    "        return params.reshape((params.shape[0] * params.shape[1], params.shape[2]))\n",
    "        \n",
    "    def _loss(self, variance):\n",
    "        # labels = (n * E)\n",
    "        labels = np.tile(self.y_train, self.E)\n",
    "        params = self._get_embeddings(variance)\n",
    "        \n",
    "        # get predictions\n",
    "        preds = np.array([self._get_meas(param) for param in params])\n",
    "        # get loss\n",
    "        return mean_squared_error(preds, labels)\n",
    "    \n",
    "    def train(self):\n",
    "        result = scipy.optimize.minimize(self._loss, x0=1.0, method=\"COBYLA\")\n",
    "        self.variance = result['x']\n",
    "        print(result)\n",
    "        \n",
    "    def test_accuracy(self):\n",
    "        stddev = self.variance ** 2\n",
    "        n = self.X_test.shape[0]\n",
    "        omega = np.random.normal(0.0, stddev, (self.p, self.q)) * self.mask.reshape((self.p, self.q))\n",
    "        beta = np.random.uniform(0.0, 2 * np.pi, (self.q,))\n",
    "        \n",
    "        params = self.X_test.dot(omega)\n",
    "        preds = np.array([self._get_meas(param) for param in params])\n",
    "        return (np.sum(preds == self.y_test)/preds.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoQubitQks = TwoQubitQks(X_tr, y_tr, X_te, y_te, episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow: auto; white-space: pre;\">0: ───Rx(π)───@───────\n",
       "              │\n",
       "1: ───Rx(π)───X───M───</pre>"
      ],
      "text/plain": [
       "0: ───Rx(π)───@───────\n",
       "              │\n",
       "1: ───Rx(π)───X───M───"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoQubitQks._get_ansatz([np.pi, np.pi], draw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the circuit over 1600 samples and test over 400 samples from the test set. We only optimize over the variance  of the normal distribution in this example. Wilson et al. achieved over 96% accuracy when trained over 10K episodes, this example is for demonstrating QKS and we did not train the model fully in the intrests of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 2.00525\n",
      "   maxcv: 0.0\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 23\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array(-1.08193125)\n"
     ]
    }
   ],
   "source": [
    "twoQubitQks.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoQubitQks.test_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "[1] Wilson, C.M., Otterbach, J.S., Tezak, N., Smith, R.S., Polloreno, A.M., Karalekas, P.J., Heidel, S., Alam, M.S., Crooks, G.E. and da Silva, M.P., 2018. Quantum kitchen sinks: An algorithm for machine learning on near-term quantum computers. arXiv preprint arXiv:1806.08321."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
